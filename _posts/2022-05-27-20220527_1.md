---
title:  "Apache Hadoop 시작하기 – PART 2 : Pseudo Distribted 모드 설정하기"
permalink: /posts/:title/
last_modified_at: 2022-05-27T21:02:00+09:00
---

(하둡 완벽가이드 4판을 보고 직접 학습용으로 정리한 내용입니다.)

하둡에는 크게 세 가지 모드가 있다.

1.	Local (독립모드)
- 데몬이 실행되지 않고 모든 것이 단독 JVM 내에서 실행된다. 개발 단계에서 mapreduce 프로그램을 실행할 때 적합. 
2.	Pseudo Distributed (가상분산모드)
- 로컬에서 모든 하둡 데몬을 실행한다. 개인적으로 단독환경을 구성하고 있는 필자가 사용할 모드이다.
3.	Fully Distributed (완전분산모드)
- 하둡 데몬을 여러대의 머신으로 구성된 클러스터에서 실행하는데, 쉽게 말하면 여러대의 서버나 PC를 한대 묶어서 데몬을 실행시킨다고 생각하면된다. 실제 기업에서는 이 모드를 많이 사용해서 작업을 할 것이기 때문에 완전분산모드에 익숙해지는게 좋지만 환경이 일단 불가능 하기 때문에..

가상분산모드를 먼저 구축해보고 익숙해지면 가상머신을 이용해서 한 대의 로컬PC로 완전 분산모드를 이용해 볼 것이다.

Hadoop Pseudo-distributed mode(가상분산모드) 구축하기(wsl ubuntu)

https://kontext.tech/article/445/install-hadoop-330-on-windows-10-using-wsl

환경설정 법이 버전이 업데이트됨에 따라서 바 뀔수 있으므로 공식 사이트 에서 설정법을 보고 따라하자.

https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html


---
1. etc/hadoop/hadoop-env.sh 수정
---
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    export HDFS_NAMENODE_USER=seunghyeok
    export HDFS_DATANODE_USER=seunghyeok
    export HDFS_SECONDARYNAMENODE_USER=seunghyeok
    export YARN_RESOURCEMANAGER_USER=seunghyeok
    export YARN_NODEMANAGER_USER=seunghyeok

자바경로를 여기에도 추가해주어야 hdfs 가 실행시에 자바 경로를 찾는다. ~/.bashrc에 있는 JAVA_HOME은 무시하는 것 같다. 그리고 root 계정을 사용하지않을 경우에 각 노드 유저를 지정해주어야한다. 

---
2.	~/.bashrc 수정
---
    export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

위 라인을 추가해서 하둡 설정파일의 위치를 지정해준다.

---
3. etc/hadoop/core-site.xml 수정
---
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://localhost:9000</value>
        </property>
    </configuration>


위 항목 추가

---
4.	etc/hadoop/hdfs-site.xml 수정
---
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
    </configuration>
위 항목 추가

---
5.	ssh key 초기화하기
---
    ssh localhost

    ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    chmod 0600 ~/.ssh/authorized_keys

wsl 에서는 service 명령어를 이용해서 ssh를 실행시켜주어야한다.
service ssh status
service ssh start
스테이터스를 확인해서 실행중이 아니면 start 시켜주자

---
6.	hdfs 실행하기
---
    sbin/start-dfs.sh

실행했는데 rcmd 소캣 오류가 떠서

    export PDSH_RCMD_TYPE=ssh

를 ~/.bashrc 와 hadoop-env.sh 에 모두 추가해 주었다.

제대로 실행되면 다음과 같고 jps 명령어를 통해서 각 노드들이 잘 살아있는지 확인이 가능하다. jps 는 현재 실행중인 JVM 의 목록을 보여준다.
    sudo sbin/start-dfs.sh
    >>
    Starting namenodes on [localhost]
    Starting datanodes
    Starting secondary namenodes [DESKTOP-C1AVPVA]

    jps
    >>
    498 DataNode
    952 Jps
    282 NameNode
    767 SecondaryNameNode
---
7.	etc/hadoop/mapred-site.xml 수정
---
맵리듀스 환경설정을 해준다.
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
       <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
위 항목 추가

---
8.	etc/hadoop/yarn-site.xml 수정
---
yarn 환경설정을 해준다.
    <configuration>
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <property>
            <name>yarn.nodemanager.env-whitelist</name>
            <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
        </property>
    </configuration>
위 항목 추가

---
9.	YARN 실행하기
---
    sudo sbin/start-yarn.sh
    >>
    Starting resourcemanager
    Starting nodemanagers

    jps
    >>
    498 DataNode
    1555 NodeManager
    1189 ResourceManager
    282 NameNode
    1771 Jps
    767 SecondaryNameNode

정상적으로 실행되면 NodeManager 데몬과 ResourceManager데몬을 jps로 확인 할 수 있다. 


---
10.	 맵리듀스 데몬 구동하기
---

종료할때는 역순으로 stop 시켜주면된다.
맵리듀스 잡 종료 후
sudo sbin/stop-yarn.sh
sudo sbin/stop-dfs.sh

이렇게하면 가상분산 환경이 완성된다.
