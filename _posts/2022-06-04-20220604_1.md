---
title:  "Keras 시작하기 - PART 1 : GPU 사용설정하기"
permalink: /posts/:title/
last_modified_at: 2022-06-04T22:27:00+09:00
---

아나콘다로 가상환경을 구성한 뒤에 텐서플로를 설치해 주었다. 최신버전 pip로 업그레이드 한 후에 pip로 설치해주자.

---
    pip install --upgrade pip

    pip install tensorflow
---

Tensorlow GPU 설정하기
1.	Tensorflow 프레임워크가 GPU 인식하고 있는지 확인하는 방법

from tensorflow.python.client import device_lib
	device_lib.list_local_devices()

CPU만 뜨면 인식이 안되고 있는 것.

2.	GPU 드라이버 설치
본인 GPU 에 맞는 들이버를 설치하고 cmd 창에서 

	nvidia-smi

명령어로 현재 CUDA 버전을 확인해준다.

3.	CUDA Toolkit 설치
https://developer.nvidia.com/
알맞은 버전의 CUDA Toolkit 을 설치해준다

4.	cuDNN SDK 설치
cuda Depp Leural Network library 의 약자로 개발자를 위한 GPU 전용 라이브러리를 제공한다. NVIDIA 에 가입을 한 뒤에 압축 파일을 내려받을 수 있다. 압축파일을 풀면 안에 폴더 3개가 있다. (bin, include, lib). 이제 이 폴더들을 기존에 CUDA toolkit을 받았던 폴더안에 세 폴더를 덮어쓰기 하면 된다. 기본경로(C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6)


5.	환경변수 설정하기
덮어씌웠던 폴더 세개에 대한 환경변수를 설정해 주어야 한다.
시스템 변수 Path 에 추가를 해준다.

    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin
    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\include
    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib

6.	확인하기
환경변수가 바뀌었으니 적용될 수 있도록 cmd창을 새로 킨 뒤 1번에 했던 명령어로 다시 확인을 해 보자

---
	from tensorflow.python.client import device_lib
	device_lib.list_local_devices()
    >>
    [name: "/device:CPU:0"
    device_type: "CPU"
    memory_limit: 268435456
    locality {
    }
    incarnation: 3218065663967030921
    xla_global_id: -1,
    name: "/device:GPU:0"
    device_type: "GPU"
    memory_limit: 7807696896
    locality {
    bus_id: 1
    links {
    }
    }
    ---
    incarnation: 16034679390131140252
    physical_device_desc: "device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6"
    xla_global_id: 416903419]
---

gpu가 인식되는 것을 확인 할 수 있다.
